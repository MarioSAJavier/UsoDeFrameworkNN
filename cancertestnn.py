# -*- coding: utf-8 -*-
"""CancerTestNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hogyZnjg7W-vTwTWelwNz5x4yqRJIVSN

# Módulo 2 Uso de framework o biblioteca de aprendizaje máquina para la implementación de una solución.

Mario Javier Soriano Aguilera A01384282
"""

from sklearn import datasets, model_selection
from sklearn.model_selection import train_test_split

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout
from tensorflow.keras import regularizers

import matplotlib.pyplot as plt

"""## Load Dataset"""

from google.colab import drive
drive.mount("/content/gdrive")
!pwd

from sklearn import model_selection
from sklearn.model_selection import train_test_split

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout
from tensorflow.keras import regularizers

import matplotlib.pyplot as plt

df = pd.read_csv('/content/gdrive/MyDrive/InteligenciaArtificial/MachineLearning/NN/Cancer_Data.csv')

"""Las características (features) incluyen información sobre las características visuales de las células cancerosas, como el radio medio, la textura media, el perímetro medio, el área media, la suavidad media, la compacidad media, la concavidad media, los puntos cóncavos medios, etc. Todas son variables numericas.

Las etiquetas (labels) están representadas por la columna "diagnosis" una variable categorica, que contiene dos categorías: "B" para benigno y "M" para maligno. Esta será la variable objetivo que deseas predecir.
"""

df.head()

len(df)

df.isna().sum()

df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)

df.dtypes

df.diagnosis.unique()

df.diagnosis.value_counts().plot(kind='bar', figsize=(3,4))
plt.title("Number of cars by make")
plt.ylabel('Number of cars')
plt.xlabel('Make of the cars')

df.groupby('diagnosis').size().plot(kind='pie', autopct="%0.1f %%",labels = ['B', 'M'])

df.describe()

Tcorrelation = df.corr(method='pearson')
Tcorrelation

c = df.corr()
threshold = .80
np.abs(c.values) > threshold
[f"{c.columns[i]} and {c.columns[j]}" for i, j in zip(*np.where(np.abs(c.values) > threshold)) if i < j]

labels = df[['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concave points_mean', 'texture_mean']]

"""Se realizo un análisis exploratorio rápida al dataset para poder ser utilizado para mi modelo. Se puede observar cómo están balanceadas las variables a predecir, estadística descriptiva a variables numéricas, donde se puede observar cantidad de features, media, valor máximo, valor mínimo, desviación estándar, división por cuantiles. Y una matriz de correlación entre los labels numéricos, se escogieron los 6 labels que más se repetían con una correlación del 80% (esto puede causar multicolinealidad, pero en esta entrega se busca hacer un análisis estadístico riguroso).

## Red Neuronal

Se seguirá la misma secuencia vista en clase pero con otro tipo de dataset, ahora se hará mención de cómo es que funciona la red neuronal describiendo lo que se está realizando y como es que se utilizan distintos métodos para mejorar los parámetros e hiperparámetros de la red neuronal, junto con sus resultados con respecto a la predicción.

En el siguiente código se preparan los datos para entrenar y evaluar un modelo de clasificación binaria mediante el escalado de características y la división de los datos.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X = scaler.fit_transform(labels)
y = df['diagnosis'] = np.where(df['diagnosis']=='M',1,0)
print('# of samples:', len(X))
# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=44)
print('\nX_train {}:\n{} ...'.format(X_train.shape, X_train[:5]))
print('\ny_train {}:\n{} ...'.format(y_train.shape, y_train[:5]))
# Turn 'y' classes into vectors with one-hot encoding using keras
#y_train = tf.keras.utils.to_categorical(np.array(y_train))
#y_test = tf.keras.utils.to_categorical(np.array(y_test))
print('\ny_train {}:\n{} ...'.format(y_train.shape, y_train[:5]))

"""Esta es una red neuronal con múltiples capas ocultas que utilizan la función de activación ReLU. Tiene una capa de entrada con 64 neuronas, seguida de capas ocultas con 128 neuronas cada una. Luego, hay capas adicionales con 64 neuronas. La capa de salida tiene una neurona y usa una función sigmoide. Es adecuada para problemas de clasificación binaria."""

def set_nn_model_architecture_1():
  # Define Model
  model = Sequential(name='my_sequential_model_1')
  # Hidden Layer 1: Fully-connected layer w/64 units. Need to specify the
  # expected input data shape (4,), initialize parameters, & set activation function
  model.add(Dense(units=64, input_shape=X_train[0].shape, activation='relu',
                  kernel_initializer=tf.keras.initializers.HeUniform(seed=0), # W
                  bias_initializer='ones', # b
                  name='hiddenlayer1'))
  # Rest of the hidden layers configurations (units and activations functions)
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer2'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer3'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer4'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer5'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer6'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer7'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer8'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer9'))
  model.add(Dense(units=1, activation = 'sigmoid', name='outputlayer'))
  model.summary()
  return model

model_1 = set_nn_model_architecture_1()

"""El siguiente código, está configurando dos optimizadores diferentes para el modelo de red neuronal. Uno es el optimizador Stochastic Gradient Descent (SGD) con una tasa de aprendizaje de 0.0001, y el otro es el optimizador Adam con la misma tasa de aprendizaje. Luego, se esta compilando el modelo utilizando el optimizador sgd, ya que en clase se utilizo Adam, de todas formas al final se utilizara para comparar resultados y tambien se esta especificando la función de pérdida como la entropía cruzada binaria y la métrica de precisión (accuracy) para evaluar el rendimiento del modelo durante el entrenamiento."""

# Define optimizer
sgd = tf.keras.optimizers.SGD(learning_rate=0.0001)
adam = tf.keras.optimizers.Adam(learning_rate=0.0001)

model_1.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])

"""## SGD"""

training_history_1 = model_1.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40)

"""### Learning Curve"""

def plot_acc_loss(training_history):
  plt.plot(training_history.history['accuracy'])
  plt.plot(training_history.history['val_accuracy'])
  # plt.ylim([0, 1])
  plt.title('Accuracy vs. Epochs')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Training', 'Validation'], loc='lower right')
  plt.show()
  plt.plot(training_history.history['loss'])
  plt.plot(training_history.history['val_loss'])
  plt.title('Loss vs. Epochs')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Training', 'Validation'], loc='upper right')
  plt.show()
plot_acc_loss(training_history_1)

# Evaluate the model on the test set
test_loss, test_acc = model_1.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""El modelo parece estar haciendo un progreso rapido en las primeras epocas pero luego el accuracy junto con loss tiene un estancamiento, depues empieza a mejorar un poco mas el modelo. Este tipo de optimizador SGD suele ser muy sensible en los hiperparámetros.

### Introducing Dropout and Batch Normalization to reduce Overfitting

El código define un modelo de red neuronal que utiliza batch normalization y dropout para reducir el overfitting. Este modelo tiene las mismas caracteristicas que el modelo anterior solo que ahora se esta aplicando lo anterior mencionado. batch normalization por lotes se aplica después de la quinta capa, y las capas de dropout se utilizan para evitar el overfitting durante el entrenamiento.
"""

def set_nn_model_architecture_2():
  model = Sequential(name='my_sequential_model_1')
  model.add(Dense(units=64, input_shape=X_train[0].shape, activation='relu', kernel_initializer=tf.keras.initializers.HeUniform(seed=0), bias_initializer='ones', name='hiddenlayer1'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer2'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer3'))
  model.add(Dropout(rate=0.3, seed=44, name='dropout1'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer4'))
  model.add(Dense(units=128, activation = 'relu', name='hiddenlayer5'))
  model.add(BatchNormalization(name='batch_normalization'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer6'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer7'))
  model.add(Dropout(rate=0.3, seed=44, name='dropout2'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer8'))
  model.add(Dense(units=64, activation = 'relu', name='hiddenlayer9'))
  model.add(Dense(units=1, activation = 'sigmoid', name='outputlayer'))
  model.summary()
  return model

model_2 = set_nn_model_architecture_2()

model_2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])
training_history_2 = model_2.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40)

plot_acc_loss(training_history_2)

# Evaluate the model on the test set
test_loss, test_acc = model_2.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""El modelo parece estar haciendo un mejor progreso que el anterior implementando Dropout y Batch Normalization, disminuyendo la perdida y aumentando la precisión tanto en el conjunto de entrenamiento como en el conjunto de validación a medida que avanza en las épocas, pero aun nuestro modelo no esta convergiendo que es lo que buscamos. Vemos como SGD necesita tener mas epocas o un learning rate mas alto para que tenga mejor ajuste nuestro modelo.

### Regularization using Callbacks: Earlystopping & learning rate reduction
"""

early_stopping = tf.keras.callbacks.EarlyStopping(patience = 30, mode =  "min") # if model doesn't improve its performance on validation set in 30 epochs, stop training
lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(patience = 20, factor = 0.2)

model_3 = set_nn_model_architecture_2()
model_3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

training_history_3 = model_3.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40,
                                 callbacks=[early_stopping, lr_reduction], verbose=0)
plot_acc_loss(training_history_3)

# Evaluate the model on the test set
test_loss, test_acc = model_3.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""Al implimentar las tecnicas de earlystopping, learning rate reduction, el modelo al implementar earlystopping y tener un learning rate muy bajo implementado con el optimizador SGD vemos que el ajuste del modelo se detiene pronto, siendo no muy bueno en los datos de entrenamiento y validacion pero si en los datos de prueba, se cree que esto se debe a que no se dieron proporciones adecuadas a los datos de validacion, entrenamiento y prueba. Esto sera modificado en los ultimos modelos"""

model_4 = set_nn_model_architecture_2()
model_4.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

training_history_4 = model_4.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40,
                                 callbacks=[early_stopping, lr_reduction], verbose=0)
plot_acc_loss(training_history_4)

# Evaluate the model on the test set
test_loss, test_acc = model_4.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""Se puede apreciar como ahora nuestro modelo si esta convergiendo en los graficos de accuracy y loss indicando que si identificando los patrones y aprendiendo adecuadamente nuestro modelo. Pero se esta ajustando muy lento.

## Adam
"""

model_5 = set_nn_model_architecture_1()
model_5.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])

training_history_5 = model_5.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40)

plot_acc_loss(training_history_5)

# Evaluate the model on the test set
test_loss, test_acc = model_5.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""Nuestro modelo muestra claramente overfitting"""

model_6 = set_nn_model_architecture_2()
model_6.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

training_history_6 = model_6.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40)
plot_acc_loss(training_history_6)

# Evaluate the model on the test set
test_loss, test_acc = model_6.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""Igual overfitting pero se ve mejora en la convergencia de los graficos"""

model_7 = set_nn_model_architecture_2()
model_7.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

training_history_7 = model_7.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40,
                                 callbacks=[early_stopping, lr_reduction], verbose=0)
plot_acc_loss(training_history_7)

# Evaluate the model on the test set
test_loss, test_acc = model_7.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""El modelo se detiene pero se puede ver que tenemos algo de overfitting, para evitarlo se puede hacer que tenga menos paciencia en el numero de epocas y asi podriamos lograr un mejor modelo."""

model_8 = set_nn_model_architecture_2()
model_8.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

training_history_8 = model_8.fit(X_train, y_train, epochs=800, validation_split=0.15, batch_size=40,
                                 callbacks=[early_stopping, lr_reduction], verbose=0)
plot_acc_loss(training_history_8)

# Evaluate the model on the test set
test_loss, test_acc = model_8.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""Es igual al anterior pero solo se modifico el learning rate, vemos como eso afecta al modelo mostrando un mejor accuracy y un menor loss pero se puede apreciar que tiene overfitting por como avanza la linea de validacion con la de entrenamiento

# Mejor modelo SGD
"""

early_stopping = tf.keras.callbacks.EarlyStopping(patience = 30, mode =  "min") # if model doesn't improve its performance on validation set in 30 epochs, stop training
lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(patience = 20, factor = 0.2)

def plot_acc_loss(training_history):
  plt.plot(training_history.history['accuracy'])
  plt.plot(training_history.history['val_accuracy'])
  # plt.ylim([0, 1])
  plt.title('Accuracy vs. Epochs')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Training', 'Validation'], loc='lower right')
  plt.show()
  plt.plot(training_history.history['loss'])
  plt.plot(training_history.history['val_loss'])
  plt.title('Loss vs. Epochs')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Training', 'Validation'], loc='upper right')
  plt.show()

model_9 = set_nn_model_architecture_2()
model_9.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])

training_history_9 = model_9.fit(X_train, y_train, epochs=800, validation_split=0.20, batch_size=40,
                                 callbacks=[early_stopping, lr_reduction], verbose=0)
plot_acc_loss(training_history_9)

# Evaluate the model on the test set
test_loss, test_acc = model_9.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

"""# Mejor modelo Adam"""

early_stopping = tf.keras.callbacks.EarlyStopping(patience = 15, mode =  "min") # if model doesn't improve its performance on validation set in 30 epochs, stop training
lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(patience = 10, factor = 0.2)

model_10 = set_nn_model_architecture_2()
model_10.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

training_history_10 = model_10.fit(X_train, y_train, epochs=800, validation_split=0.20, batch_size=40,
                                 callbacks=[early_stopping, lr_reduction], verbose=0)
plot_acc_loss(training_history_10)

# Evaluate the model on the test set
test_loss, test_acc = model_10.evaluate(X_test, y_test, verbose=0)
print('test_loss: {}\ntest_acc: {} %'.format(round(test_loss,4), round(test_acc*100,4)))

from sklearn.metrics import confusion_matrix

y_pred_9 = model_9.predict(X_test)
y_pred_10 = model_10.predict(X_test)

cm_9 = confusion_matrix(y_test, (y_pred_9 > 0.5))
cm_10 = confusion_matrix(y_test, (y_pred_10 > 0.5))

print("Matriz de Confusión - Modelo 9:")
print(cm_9)

print("\nMatriz de Confusión - Modelo 10:")
print(cm_10)

from sklearn.metrics import precision_score, recall_score

precision_9 = precision_score(y_test, (y_pred_9 > 0.5))
precision_10 = precision_score(y_test, (y_pred_10 > 0.5))

recall_9 = recall_score(y_test, (y_pred_9 > 0.5))
recall_10 = recall_score(y_test, (y_pred_10 > 0.5))

print("Precisión - Modelo 9:", precision_9)
print("Precisión - Modelo 10:", precision_10)

print("Sensibilidad - Modelo 9:", recall_9)
print("Sensibilidad - Modelo 10:", recall_10)

# Puedes calcular la especificidad restando los falsos positivos de los verdaderos negativos y dividiendo por el total de verdaderos negativos.
specificity_9 = cm_9[1, 1] / (cm_9[1, 0] + cm_9[1, 1])
specificity_10 = cm_10[1, 1] / (cm_10[1, 0] + cm_10[1, 1])

print("Especificidad - Modelo 9:", specificity_9)
print("Especificidad - Modelo 10:", specificity_10)

from sklearn.metrics import accuracy_score, f1_score

accuracy_9 = accuracy_score(y_test, (y_pred_9 > 0.5))
accuracy_10 = accuracy_score(y_test, (y_pred_10 > 0.5))

f1_score_9 = f1_score(y_test, (y_pred_9 > 0.5))
f1_score_10 = f1_score(y_test, (y_pred_10 > 0.5))

print("Exactitud - Modelo 9:", accuracy_9)
print("Exactitud - Modelo 10:", accuracy_10)

print("F1-Score - Modelo 9:", f1_score_9)
print("F1-Score - Modelo 10:", f1_score_10)

"""Los optimizadores SGD (Descenso de Gradiente Estocástico) y Adam (Adaptive Moment Estimation) son dos algoritmos esenciales en el aprendizaje automático. Una diferencia clave radica en la sensibilidad a la elección de la tasa de aprendizaje: SGD es más sensible a la tasa de aprendizaje, que es un hiperparámetro crítico, mientras que Adam se adapta automáticamente, reduciendo la necesidad de ajustes precisos. Esta distinción hace que Adam sea más popular en muchas aplicaciones de aprendizaje automático.

Modificando los parametros e hiperparametros como tecnicas para evitar overfitting se alcanzaron a realizar los ultimos dos modelos que muestran un accuracy de 95% pero en estos se les aumentaron a 20% de datos de prueba cosa que en los anteriores fueron de 15%.
"""